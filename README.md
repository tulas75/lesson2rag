# ğŸ“ RAG Pipeline - Lezioni Universitarie

Trasforma trascrizioni di lezioni universitarie in una knowledge base ricercabile usando RAG (Retrieval-Augmented Generation).

## âœ¨ FunzionalitÃ 

- ğŸ“¤ **Upload trascrizioni** (TXT, MD)
- ğŸ¤– **Analisi automatica** con LLM (Gemini, Claude, GPT-4, DeepSeek)
- ğŸ“š **Segmentazione** in unitÃ  didattiche discrete
- ğŸ”¢ **Generazione embeddings** multilingue
- ğŸ’¾ **Vector Store** PostgreSQL/pgvector (opzionale)
- ğŸ” **Ricerca semantica** nei contenuti
- ğŸ“Š **Visualizzazione risultati** interattiva
- ğŸ’¾ **Export JSON** completo

## ğŸš€ Quick Start

### 1. Installazione

```bash
# Clone repository (o crea nuova directory)
mkdir rag-pipeline && cd rag-pipeline

# Installa dipendenze
pip install -r requirements.txt
```

### 2. Configurazione API Keys

**Opzione A: File .env (Raccomandato)**
```bash
# Copia il file di esempio
cp .env.example .env

# Modifica .env con le tue chiavi
nano .env  # o usa il tuo editor preferito
```

**Opzione B: Interfaccia Streamlit**
- Le API keys possono essere inserite direttamente nell'interfaccia
- Valide solo per la sessione corrente

### 3. Avvio

```bash
streamlit run app.py
```

L'app si aprirÃ  automaticamente su `http://localhost:8501`

## ğŸ”‘ Ottenere le API Keys

### LLM Models

#### Google Gemini (Gratuito)
1. Vai su https://aistudio.google.com/apikey
2. Clicca "Create API Key"
3. Copia la chiave in `.env` come `GEMINI_API_KEY`

#### DeepSeek
1. Registrati su https://platform.deepseek.com/
2. Vai su API Keys
3. Copia la chiave in `.env` come `DEEPSEEK_API_KEY`

#### Anthropic Claude
1. Registrati su https://console.anthropic.com/
2. Vai su API Keys
3. Copia la chiave in `.env` come `ANTHROPIC_API_KEY`

#### OpenAI
1. Vai su https://platform.openai.com/api-keys
2. Crea una nuova API key
3. Copia la chiave in `.env` come `OPENAI_API_KEY`

### Embedding Models (opzionale)

#### ğŸ–¥ï¸ Locale (Sentence Transformers) - RACCOMANDATO
- **Gratuito** e **Privacy-first**
- Nessuna API key necessaria
- Eseguito sulla tua macchina
- Buona qualitÃ  per italiano
- **Modelli consigliati**: BAAI/bge-m3, multilingual-e5-large

#### â˜ï¸ API Providers

**OpenAI Embeddings**
- Stessa API key di OpenAI LLM
- Modelli: text-embedding-3-small, text-embedding-3-large
- Costo: ~$0.02 per 1M tokens

**Cohere Embeddings**
1. Registrati su https://dashboard.cohere.com/
2. Ottieni API key
3. Configura come `COHERE_API_KEY`
- Modelli: embed-multilingual-v3.0 (ottimo per italiano)

**Voyage AI**
1. Registrati su https://dash.voyageai.com/
2. Ottieni API key
3. Configura come `VOYAGE_API_KEY`
- Modelli: voyage-large-2, voyage-2

**Mistral**
- Usa la chiave Mistral
- Modello: mistral-embed

## ğŸ“¦ Struttura Files

```
rag-pipeline/
â”œâ”€â”€ app.py                          # Streamlit app
â”œâ”€â”€ pipeline_completa_lezioni.py    # Pipeline RAG core
â”œâ”€â”€ requirements.txt                # Dipendenze Python
â”œâ”€â”€ .env                           # Configurazione (non committare!)
â”œâ”€â”€ .env.example                   # Template configurazione
â”œâ”€â”€ output/                        # Output JSON generati
â”‚   â”œâ”€â”€ *_analisi.json
â”‚   â””â”€â”€ *_unita.json
â””â”€â”€ temp/                          # File temporanei upload
```

## ğŸ¯ Come Usare

### ğŸ†š Embedding: Locale vs API - Quale scegliere?

| Criterio | ğŸ–¥ï¸ Locale (Sentence Transformers) | â˜ï¸ API (OpenAI/Cohere/Voyage) |
|----------|-----------------------------------|-------------------------------|
| **Costo** | âœ… Gratuito | âŒ A pagamento (~$0.01-0.05/lezione) |
| **Privacy** | âœ… Tutto locale, nessun dato inviato | âš ï¸ Testi inviati al provider |
| **VelocitÃ ** | âš ï¸ Dipende da CPU/GPU | âœ… Molto veloce |
| **QualitÃ ** | âœ… Ottima per italiano (bge-m3) | âœ… Eccellente |
| **Setup** | âš ï¸ Richiede download modello (1-2 GB) | âœ… Immediato con API key |
| **RAM** | âš ï¸ 2-8 GB | âœ… Minima |
| **Internet** | âœ… Solo per download iniziale | âŒ Necessaria sempre |

**Raccomandazioni:**
- ğŸ“ **Studenti/Ricercatori**: Locale (gratuito, privacy)
- ğŸ¢ **Aziende con budget**: API (veloce, scalabile)
- ğŸ”’ **Dati sensibili**: SEMPRE locale
- âš¡ **Produzione/grandi volumi**: API (piÃ¹ veloce)

### Step 1: Configurazione Sidebar
1. **Seleziona modello LLM** (es: Gemini 2.5 Flash)
2. **Inserisci API Key LLM** (o carica da .env)
3. **Test connessione LLM** (opzionale ma raccomandato)
4. **Scegli tipo embedding**:
   - ğŸ–¥ï¸ **Locale**: Gratuito, privacy-first, eseguito sulla tua macchina
   - â˜ï¸ **API**: PiÃ¹ veloce, richiede API key e crediti
5. **Configura embedding model**
6. **Opzionale:** Abilita Vector Store PostgreSQL

### Step 2: Upload & Process
1. Carica file trascrizione (.txt o .md)
2. Dai un nome alla lezione
3. Clicca "ğŸš€ Avvia Elaborazione"
4. Attendi completamento (puÃ² richiedere alcuni minuti)

### Step 3: Visualizza Risultati
- **Analisi strutturale**: Overview, concetti, struttura
- **UnitÃ  didattiche**: Testo, concetti, domande
- **Export JSON**: Salva risultati completi

### Step 4: Ricerca (se Vector Store attivo)
1. Vai al tab "ğŸ” Ricerca"
2. Inserisci domanda in linguaggio naturale
3. Ottieni risultati semanticamente rilevanti

## âš™ï¸ Configurazione PostgreSQL (Opzionale)

Se vuoi usare il Vector Store per ricerca semantica:

```bash
# Installa PostgreSQL con pgvector
# Ubuntu/Debian:
sudo apt-get install postgresql postgresql-contrib

# macOS:
brew install postgresql

# Crea database
createdb pandino

# Abilita estensione pgvector
psql pandino -c "CREATE EXTENSION vector;"
```

Configura in `.env`:
```bash
PGHOST=localhost
PGPORT=5432
PGUSER=postgres
PGPASSWORD=your_password
PGDATABASE=pandino
```

## ğŸ§ª Test Rapido

```bash
# Test senza Vector Store (piÃ¹ veloce)
# 1. Inserisci API key Gemini nella sidebar
# 2. Carica una trascrizione breve
# 3. NON abilitare Vector Store
# 4. Avvia elaborazione

# Tempo stimato: 2-5 minuti per lezione di 5000 parole
```

## ğŸ“Š Output Generati

### 1. Analisi Strutturale
```json
{
  "titolo_lezione": "...",
  "argomento_generale": "...",
  "struttura_macro": [...],
  "concetti_chiave": [...],
  "terminologia_tecnica": [...]
}
```

### 2. UnitÃ  Didattiche
```json
{
  "unita_concettuali": [
    {
      "id": "U001",
      "titolo_unita": "...",
      "testo_riformulato": "...",
      "concetti_principali": [...],
      "domande_studente_tipiche": [...]
    }
  ]
}
```

## ğŸ”§ Parametri Avanzati

### Batch Size
- **8-16**: PiÃ¹ lento, meno memoria
- **32** (default): Bilanciato
- **64**: PiÃ¹ veloce, piÃ¹ memoria

### Modelli Embedding
- **BAAI/bge-m3** (Locale): Ottimo per italiano, veloce, GRATUITO
- **multilingual-e5-large** (Locale): PiÃ¹ accurato, piÃ¹ lento, GRATUITO
- **text-embedding-3-small** (OpenAI): Veloce, economico (~$0.02/1M tokens)
- **embed-multilingual-v3.0** (Cohere): Eccellente per italiano
- **voyage-large-2** (Voyage): Alta qualitÃ , costoso

### Modelli LLM
- **Gemini 2.5 Flash**: Veloce, economico, buona qualitÃ 
- **Claude Sonnet**: Eccellente qualitÃ , piÃ¹ costoso
- **GPT-4o**: Ottimo bilanciamento
- **DeepSeek**: Economico, buono per task semplici

## â— Troubleshooting

### "API Key non valida"
- Verifica che la chiave sia copiata correttamente (no spazi)
- Controlla di avere crediti disponibili
- Usa il test connessione nella sidebar

### "Out of memory"
- Riduci batch_size (es: 16 o 8)
- Usa modello embedding piÃ¹ leggero
- Processa trascrizioni piÃ¹ brevi

### "Elaborazione troppo lenta"
- Usa Gemini Flash invece di Claude/GPT-4
- Aumenta batch_size se hai RAM disponibile
- Verifica connessione internet

### "Vector Store non funziona"
- Verifica che PostgreSQL sia in esecuzione
- Controlla che l'estensione pgvector sia installata
- Verifica credenziali database

## ğŸ’¡ Best Practices

1. **Primo test**: Usa Gemini Flash + embeddings locali (GRATUITO)
2. **Trascrizioni pulite**: Rimuovi header/footer non necessari
3. **Nomi descrittivi**: Usa nomi lezione chiari (es: "Statistica - Lezione 3")
4. **Backup JSON**: Salva sempre i risultati prima di chiudere
5. **API Keys**: Non condividere mai le chiavi, usa .env
6. **Embeddings**: Inizia con locali (gratis), passa ad API solo se serve velocitÃ 
7. **Costi**: Embedding locali = $0, OpenAI ~$0.02/lezione, Cohere ~$0.01/lezione

## ğŸ“ TODO / Roadmap

- [ ] Supporto batch processing multiple lezioni
- [ ] Export in Markdown/PDF
- [ ] Grafici analisi temporale lezioni
- [ ] Integrazione con LMS (Moodle, Canvas)
- [ ] Generazione automatica quiz
- [ ] Confronto tra lezioni

## ğŸ¤ Contributi

PRs benvenute! Per modifiche importanti, apri prima un issue.

## ğŸ“„ Licenza

MIT License - vedi LICENSE file

## ğŸ†˜ Supporto

- ğŸ“§ Email: [tua-email@example.com]
- ğŸ› Issues: GitHub Issues
- ğŸ’¬ Discussioni: GitHub Discussions

---

**Fatto con â¤ï¸ per l'educazione universitaria**
